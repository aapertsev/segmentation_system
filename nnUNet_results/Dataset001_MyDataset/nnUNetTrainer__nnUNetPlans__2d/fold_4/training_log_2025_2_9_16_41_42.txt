
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-09 16:41:42.728458: do_dummy_2d_data_aug: False 
2025-02-09 16:41:42.729130: Creating new 5-fold cross-validation split... 
2025-02-09 16:41:42.730563: Desired fold for training: 4 
2025-02-09 16:41:42.730627: This split has 138 training and 34 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 8, 'patch_size': [448, 512], 'median_image_size_in_voxels': [408.0, 512.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_MyDataset', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 408, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 107.11954498291016, 'median': 110.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 162.0, 'std': 25.942211151123047}}} 
 
2025-02-09 16:42:01.331909: unpacking dataset... 
2025-02-09 16:42:06.640523: unpacking done... 
2025-02-09 16:42:09.897156: Unable to plot network architecture: 
2025-02-09 16:42:09.897418: module 'torch.onnx' has no attribute '_optimize_graph' 
2025-02-09 16:42:09.917831:  
2025-02-09 16:42:09.918087: Epoch 0 
2025-02-09 16:42:09.918433: Current learning rate: 0.01 
2025-02-09 16:48:45.226204: train_loss -0.0328 
2025-02-09 16:48:45.228317: val_loss -0.3944 
2025-02-09 16:48:45.228439: Pseudo dice [0.0, 0.9258, 0.0] 
2025-02-09 16:48:45.229152: Epoch time: 395.31 s 
2025-02-09 16:48:45.229291: Yayy! New best EMA pseudo Dice: 0.3086 
2025-02-09 16:48:47.421865:  
2025-02-09 16:48:47.422095: Epoch 1 
2025-02-09 16:48:47.422201: Current learning rate: 0.00999 
2025-02-09 16:55:13.511993: train_loss -0.5761 
2025-02-09 16:55:13.514294: val_loss -0.6792 
2025-02-09 16:55:13.514407: Pseudo dice [0.8817, 0.9625, 0.4369] 
2025-02-09 16:55:13.515089: Epoch time: 386.09 s 
2025-02-09 16:55:13.515210: Yayy! New best EMA pseudo Dice: 0.3538 
2025-02-09 16:55:15.189068:  
2025-02-09 16:55:15.189395: Epoch 2 
2025-02-09 16:55:15.189494: Current learning rate: 0.00998 
2025-02-09 17:01:40.396641: train_loss -0.7574 
2025-02-09 17:01:40.398978: val_loss -0.7979 
2025-02-09 17:01:40.399121: Pseudo dice [0.9233, 0.9569, 0.7502] 
2025-02-09 17:01:40.399946: Epoch time: 385.21 s 
2025-02-09 17:01:40.400347: Yayy! New best EMA pseudo Dice: 0.4061 
2025-02-09 17:01:42.619042:  
2025-02-09 17:01:42.619223: Epoch 3 
2025-02-09 17:01:42.619320: Current learning rate: 0.00997 
2025-02-09 17:08:08.913909: train_loss -0.8298 
2025-02-09 17:08:08.916475: val_loss -0.8073 
2025-02-09 17:08:08.916632: Pseudo dice [0.9454, 0.9633, 0.7311] 
2025-02-09 17:08:08.917339: Epoch time: 386.3 s 
2025-02-09 17:08:08.917442: Yayy! New best EMA pseudo Dice: 0.4535 
2025-02-09 17:08:10.534129:  
2025-02-09 17:08:10.534466: Epoch 4 
2025-02-09 17:08:10.534565: Current learning rate: 0.00996 
2025-02-09 17:14:33.994069: train_loss -0.8518 
2025-02-09 17:14:33.996389: val_loss -0.8107 
2025-02-09 17:14:33.996594: Pseudo dice [0.9278, 0.9614, 0.7533] 
2025-02-09 17:14:33.996760: Epoch time: 383.46 s 
2025-02-09 17:14:33.996867: Yayy! New best EMA pseudo Dice: 0.4962 
2025-02-09 17:14:35.607766:  
2025-02-09 17:14:35.608229: Epoch 5 
2025-02-09 17:14:35.608362: Current learning rate: 0.00995 
2025-02-09 17:20:59.765505: train_loss -0.8539 
2025-02-09 17:20:59.767731: val_loss -0.8361 
2025-02-09 17:20:59.767867: Pseudo dice [0.9449, 0.9671, 0.7831] 
2025-02-09 17:20:59.768527: Epoch time: 384.16 s 
2025-02-09 17:20:59.768940: Yayy! New best EMA pseudo Dice: 0.5364 
2025-02-09 17:21:01.448758:  
2025-02-09 17:21:01.448976: Epoch 6 
2025-02-09 17:21:01.449096: Current learning rate: 0.00995 
2025-02-09 17:27:27.558474: train_loss -0.8753 
2025-02-09 17:27:27.560515: val_loss -0.8593 
2025-02-09 17:27:27.560615: Pseudo dice [0.9461, 0.9674, 0.809] 
2025-02-09 17:27:27.561155: Epoch time: 386.11 s 
2025-02-09 17:27:27.561394: Yayy! New best EMA pseudo Dice: 0.5735 
2025-02-09 17:27:29.385368:  
2025-02-09 17:27:29.385929: Epoch 7 
2025-02-09 17:27:29.386036: Current learning rate: 0.00994 
2025-02-09 17:33:59.383267: train_loss -0.8726 
2025-02-09 17:33:59.386414: val_loss -0.8474 
2025-02-09 17:33:59.386538: Pseudo dice [0.9479, 0.9665, 0.773] 
2025-02-09 17:33:59.387723: Epoch time: 390.0 s 
2025-02-09 17:33:59.387815: Yayy! New best EMA pseudo Dice: 0.6058 
2025-02-09 17:34:01.156584:  
2025-02-09 17:34:01.156962: Epoch 8 
2025-02-09 17:34:01.157061: Current learning rate: 0.00993 
2025-02-09 17:40:37.188815: train_loss -0.8793 
2025-02-09 17:40:37.191448: val_loss -0.8392 
2025-02-09 17:40:37.191555: Pseudo dice [0.9473, 0.9704, 0.7755] 
2025-02-09 17:40:37.192110: Epoch time: 396.03 s 
2025-02-09 17:40:37.192202: Yayy! New best EMA pseudo Dice: 0.635 
2025-02-09 17:40:39.015792:  
2025-02-09 17:40:39.016230: Epoch 9 
2025-02-09 17:40:39.016361: Current learning rate: 0.00992 
2025-02-09 17:47:08.725219: train_loss -0.8855 
2025-02-09 17:47:08.728565: val_loss -0.8604 
2025-02-09 17:47:08.729017: Pseudo dice [0.9515, 0.9693, 0.8033] 
2025-02-09 17:47:08.729719: Epoch time: 389.71 s 
2025-02-09 17:47:08.729866: Yayy! New best EMA pseudo Dice: 0.6623 
2025-02-09 17:47:10.519214:  
2025-02-09 17:47:10.519835: Epoch 10 
2025-02-09 17:47:10.519975: Current learning rate: 0.00991 
2025-02-09 17:53:37.790181: train_loss -0.8781 
2025-02-09 17:53:37.792415: val_loss -0.8228 
2025-02-09 17:53:37.792677: Pseudo dice [0.9488, 0.9663, 0.7569] 
2025-02-09 17:53:37.793465: Epoch time: 387.27 s 
2025-02-09 17:53:37.793634: Yayy! New best EMA pseudo Dice: 0.6851 
2025-02-09 17:53:40.603149:  
2025-02-09 17:53:40.603382: Epoch 11 
2025-02-09 17:53:40.603493: Current learning rate: 0.0099 
2025-02-09 18:00:08.102136: train_loss -0.8827 
2025-02-09 18:00:08.104601: val_loss -0.8315 
2025-02-09 18:00:08.104754: Pseudo dice [0.9471, 0.9639, 0.7738] 
2025-02-09 18:00:08.105514: Epoch time: 387.5 s 
2025-02-09 18:00:08.105702: Yayy! New best EMA pseudo Dice: 0.7061 
2025-02-09 18:00:09.723608:  
2025-02-09 18:00:09.723804: Epoch 12 
2025-02-09 18:00:09.723904: Current learning rate: 0.00989 
2025-02-09 18:06:33.849357: train_loss -0.8923 
2025-02-09 18:06:33.852383: val_loss -0.8619 
2025-02-09 18:06:33.852600: Pseudo dice [0.9516, 0.967, 0.8098] 
2025-02-09 18:06:33.853774: Epoch time: 384.13 s 
2025-02-09 18:06:33.853923: Yayy! New best EMA pseudo Dice: 0.7264 
2025-02-09 18:06:35.607885:  
2025-02-09 18:06:35.608283: Epoch 13 
2025-02-09 18:06:35.608408: Current learning rate: 0.00988 
2025-02-09 18:12:59.838585: train_loss -0.8885 
2025-02-09 18:12:59.842461: val_loss -0.8538 
2025-02-09 18:12:59.842603: Pseudo dice [0.9512, 0.9684, 0.7885] 
2025-02-09 18:12:59.843597: Epoch time: 384.23 s 
2025-02-09 18:12:59.843739: Yayy! New best EMA pseudo Dice: 0.7441 
2025-02-09 18:13:01.560889:  
2025-02-09 18:13:01.561291: Epoch 14 
2025-02-09 18:13:01.561486: Current learning rate: 0.00987 
2025-02-09 18:19:25.492161: train_loss -0.8846 
2025-02-09 18:19:25.495218: val_loss -0.8603 
2025-02-09 18:19:25.495381: Pseudo dice [0.9433, 0.9678, 0.8151] 
2025-02-09 18:19:25.496219: Epoch time: 383.93 s 
2025-02-09 18:19:25.496318: Yayy! New best EMA pseudo Dice: 0.7605 
2025-02-09 18:19:27.209650:  
2025-02-09 18:19:27.210071: Epoch 15 
2025-02-09 18:19:27.210204: Current learning rate: 0.00986 
2025-02-09 18:25:52.123057: train_loss -0.8919 
2025-02-09 18:25:52.126064: val_loss -0.8771 
2025-02-09 18:25:52.126215: Pseudo dice [0.9488, 0.9697, 0.8486] 
2025-02-09 18:25:52.127395: Epoch time: 384.91 s 
2025-02-09 18:25:52.127561: Yayy! New best EMA pseudo Dice: 0.7767 
2025-02-09 18:25:53.776226:  
2025-02-09 18:25:53.776616: Epoch 16 
2025-02-09 18:25:53.776714: Current learning rate: 0.00986 
2025-02-09 18:32:20.259653: train_loss -0.8988 
2025-02-09 18:32:20.262415: val_loss -0.8793 
2025-02-09 18:32:20.262540: Pseudo dice [0.9456, 0.9707, 0.8408] 
2025-02-09 18:32:20.263236: Epoch time: 386.48 s 
2025-02-09 18:32:20.263412: Yayy! New best EMA pseudo Dice: 0.7909 
2025-02-09 18:32:21.982833:  
2025-02-09 18:32:21.983298: Epoch 17 
2025-02-09 18:32:21.983414: Current learning rate: 0.00985 
2025-02-09 18:38:49.601209: train_loss -0.9041 
2025-02-09 18:38:49.603439: val_loss -0.8786 
2025-02-09 18:38:49.603592: Pseudo dice [0.9476, 0.9729, 0.8378] 
2025-02-09 18:38:49.604331: Epoch time: 387.62 s 
2025-02-09 18:38:49.604475: Yayy! New best EMA pseudo Dice: 0.8038 
2025-02-09 18:38:52.230420:  
2025-02-09 18:38:52.230603: Epoch 18 
2025-02-09 18:38:52.230728: Current learning rate: 0.00984 
2025-02-09 18:45:17.814085: train_loss -0.9082 
2025-02-09 18:45:17.816655: val_loss -0.8759 
2025-02-09 18:45:17.816803: Pseudo dice [0.948, 0.9711, 0.8366] 
2025-02-09 18:45:17.817490: Epoch time: 385.58 s 
2025-02-09 18:45:17.817655: Yayy! New best EMA pseudo Dice: 0.8153 
2025-02-09 18:45:19.532765:  
2025-02-09 18:45:19.533332: Epoch 19 
2025-02-09 18:45:19.533513: Current learning rate: 0.00983 
2025-02-09 18:51:46.052737: train_loss -0.8989 
2025-02-09 18:51:46.055574: val_loss -0.8793 
2025-02-09 18:51:46.055742: Pseudo dice [0.9483, 0.9724, 0.8529] 
2025-02-09 18:51:46.056456: Epoch time: 386.52 s 
2025-02-09 18:51:46.056662: Yayy! New best EMA pseudo Dice: 0.8262 
2025-02-09 18:51:47.692932:  
2025-02-09 18:51:47.693374: Epoch 20 
2025-02-09 18:51:47.693506: Current learning rate: 0.00982 
2025-02-09 18:58:09.782110: train_loss -0.8874 
2025-02-09 18:58:09.784406: val_loss -0.8598 
2025-02-09 18:58:09.784510: Pseudo dice [0.9456, 0.971, 0.8099] 
2025-02-09 18:58:09.785092: Epoch time: 382.09 s 
2025-02-09 18:58:09.785201: Yayy! New best EMA pseudo Dice: 0.8345 
2025-02-09 18:58:11.491124:  
2025-02-09 18:58:11.491530: Epoch 21 
2025-02-09 18:58:11.491645: Current learning rate: 0.00981 
2025-02-09 19:04:36.234598: train_loss -0.8905 
2025-02-09 19:04:36.236987: val_loss -0.8587 
2025-02-09 19:04:36.237136: Pseudo dice [0.9481, 0.9693, 0.8272] 
2025-02-09 19:04:36.237969: Epoch time: 384.74 s 
2025-02-09 19:04:36.238112: Yayy! New best EMA pseudo Dice: 0.8425 
2025-02-09 19:04:37.968046:  
2025-02-09 19:04:37.968266: Epoch 22 
2025-02-09 19:04:37.968386: Current learning rate: 0.0098 
2025-02-09 19:11:22.057848: train_loss -0.9034 
2025-02-09 19:11:22.060228: val_loss -0.8477 
2025-02-09 19:11:22.060437: Pseudo dice [0.9454, 0.9699, 0.805] 
2025-02-09 19:11:22.061128: Epoch time: 404.09 s 
2025-02-09 19:11:22.061320: Yayy! New best EMA pseudo Dice: 0.8489 
2025-02-09 19:11:23.756837:  
2025-02-09 19:11:23.757076: Epoch 23 
2025-02-09 19:11:23.757182: Current learning rate: 0.00979 
2025-02-09 19:17:56.373889: train_loss -0.9051 
2025-02-09 19:17:56.376060: val_loss -0.8671 
2025-02-09 19:17:56.376199: Pseudo dice [0.9511, 0.972, 0.7954] 
2025-02-09 19:17:56.376829: Epoch time: 392.62 s 
2025-02-09 19:17:56.376931: Yayy! New best EMA pseudo Dice: 0.8547 
2025-02-09 19:17:58.085803:  
2025-02-09 19:17:58.086008: Epoch 24 
2025-02-09 19:17:58.086224: Current learning rate: 0.00978 
2025-02-09 19:24:33.756369: train_loss -0.9112 
2025-02-09 19:24:33.759368: val_loss -0.8469 
2025-02-09 19:24:33.759633: Pseudo dice [0.952, 0.9724, 0.8147] 
2025-02-09 19:24:33.760762: Epoch time: 395.67 s 
2025-02-09 19:24:33.760894: Yayy! New best EMA pseudo Dice: 0.8605 
2025-02-09 19:24:35.696972:  
2025-02-09 19:24:35.697192: Epoch 25 
2025-02-09 19:24:35.697308: Current learning rate: 0.00977 
2025-02-09 19:31:17.356754: train_loss -0.9105 
2025-02-09 19:31:17.359767: val_loss -0.8711 
2025-02-09 19:31:17.359992: Pseudo dice [0.9424, 0.9725, 0.8371] 
2025-02-09 19:31:17.360971: Epoch time: 401.66 s 
2025-02-09 19:31:17.361259: Yayy! New best EMA pseudo Dice: 0.8662 
2025-02-09 19:31:19.311244:  
2025-02-09 19:31:19.311810: Epoch 26 
2025-02-09 19:31:19.311925: Current learning rate: 0.00977 
2025-02-09 19:37:55.370357: train_loss -0.9103 
2025-02-09 19:37:55.373694: val_loss -0.8817 
2025-02-09 19:37:55.373899: Pseudo dice [0.947, 0.9715, 0.8475] 
2025-02-09 19:37:55.374743: Epoch time: 396.06 s 
2025-02-09 19:37:55.375035: Yayy! New best EMA pseudo Dice: 0.8718 
2025-02-09 19:38:00.201116:  
2025-02-09 19:38:00.201412: Epoch 27 
2025-02-09 19:38:00.201649: Current learning rate: 0.00976 
2025-02-09 19:44:44.311379: train_loss -0.9089 
2025-02-09 19:44:44.316418: val_loss -0.8859 
2025-02-09 19:44:44.316813: Pseudo dice [0.9414, 0.9744, 0.8557] 
2025-02-09 19:44:44.318036: Epoch time: 404.11 s 
2025-02-09 19:44:44.318175: Yayy! New best EMA pseudo Dice: 0.877 
2025-02-09 19:44:46.375315:  
2025-02-09 19:44:46.375567: Epoch 28 
2025-02-09 19:44:46.375703: Current learning rate: 0.00975 
2025-02-09 19:51:44.251959: train_loss -0.9105 
2025-02-09 19:51:44.255267: val_loss -0.8868 
2025-02-09 19:51:44.255467: Pseudo dice [0.9527, 0.9734, 0.8399] 
2025-02-09 19:51:44.256122: Epoch time: 417.88 s 
2025-02-09 19:51:44.256227: Yayy! New best EMA pseudo Dice: 0.8815 
2025-02-09 19:51:46.399641:  
2025-02-09 19:51:46.399988: Epoch 29 
2025-02-09 19:51:46.400372: Current learning rate: 0.00974 
2025-02-09 19:58:46.612113: train_loss -0.9026 
2025-02-09 19:58:46.614879: val_loss -0.8725 
2025-02-09 19:58:46.615196: Pseudo dice [0.9452, 0.9705, 0.8415] 
2025-02-09 19:58:46.616215: Epoch time: 420.21 s 
2025-02-09 19:58:46.616486: Yayy! New best EMA pseudo Dice: 0.8852 
2025-02-09 19:58:49.051473:  
2025-02-09 19:58:49.052042: Epoch 30 
2025-02-09 19:58:49.052166: Current learning rate: 0.00973 
2025-02-09 20:05:32.686496: train_loss -0.9127 
2025-02-09 20:05:32.689344: val_loss -0.8875 
2025-02-09 20:05:32.689491: Pseudo dice [0.9493, 0.9718, 0.8556] 
2025-02-09 20:05:32.690272: Epoch time: 403.64 s 
2025-02-09 20:05:32.690551: Yayy! New best EMA pseudo Dice: 0.8893 
2025-02-09 20:05:34.595024:  
2025-02-09 20:05:34.595235: Epoch 31 
2025-02-09 20:05:34.595341: Current learning rate: 0.00972 
2025-02-09 20:12:12.522271: train_loss -0.9099 
2025-02-09 20:12:12.525254: val_loss -0.8546 
2025-02-09 20:12:12.525375: Pseudo dice [0.9457, 0.9712, 0.8068] 
2025-02-09 20:12:12.526675: Epoch time: 397.93 s 
2025-02-09 20:12:12.526767: Yayy! New best EMA pseudo Dice: 0.8911 
2025-02-09 20:12:14.466973:  
2025-02-09 20:12:14.467423: Epoch 32 
2025-02-09 20:12:14.467541: Current learning rate: 0.00971 
2025-02-09 20:18:53.031033: train_loss -0.9105 
2025-02-09 20:18:53.035161: val_loss -0.8797 
2025-02-09 20:18:53.035716: Pseudo dice [0.9513, 0.9716, 0.8255] 
2025-02-09 20:18:53.037051: Epoch time: 398.56 s 
2025-02-09 20:18:53.037254: Yayy! New best EMA pseudo Dice: 0.8936 
2025-02-09 20:18:55.168754:  
2025-02-09 20:18:55.169210: Epoch 33 
2025-02-09 20:18:55.169359: Current learning rate: 0.0097 
2025-02-09 20:26:40.831782: train_loss -0.907 
2025-02-09 20:26:40.836628: val_loss -0.8622 
2025-02-09 20:26:40.836742: Pseudo dice [0.948, 0.971, 0.8215] 
2025-02-09 20:26:40.842106: Epoch time: 465.66 s 
2025-02-09 20:26:40.842236: Yayy! New best EMA pseudo Dice: 0.8956 
2025-02-09 20:26:43.178946:  
2025-02-09 20:26:43.179293: Epoch 34 
2025-02-09 20:26:43.179395: Current learning rate: 0.00969 
2025-02-09 20:34:00.134817: train_loss -0.9126 
2025-02-09 20:34:00.138366: val_loss -0.8798 
2025-02-09 20:34:00.138727: Pseudo dice [0.9527, 0.9741, 0.8354] 
2025-02-09 20:34:00.139319: Epoch time: 436.96 s 
2025-02-09 20:34:00.139436: Yayy! New best EMA pseudo Dice: 0.8981 
2025-02-09 20:34:03.853792:  
2025-02-09 20:34:03.854051: Epoch 35 
2025-02-09 20:34:03.854194: Current learning rate: 0.00968 
2025-02-09 20:41:04.363875: train_loss -0.9104 
2025-02-09 20:41:04.367619: val_loss -0.8579 
2025-02-09 20:41:04.367964: Pseudo dice [0.9473, 0.9734, 0.8177] 
2025-02-09 20:41:04.369232: Epoch time: 420.51 s 
2025-02-09 20:41:04.369517: Yayy! New best EMA pseudo Dice: 0.8996 
2025-02-09 20:41:10.159473:  
2025-02-09 20:41:10.159781: Epoch 36 
2025-02-09 20:41:10.159889: Current learning rate: 0.00968 
2025-02-09 20:48:06.257173: train_loss -0.9155 
2025-02-09 20:48:06.261705: val_loss -0.8714 
2025-02-09 20:48:06.262020: Pseudo dice [0.9496, 0.9713, 0.8212] 
2025-02-09 20:48:06.262950: Epoch time: 416.1 s 
2025-02-09 20:48:06.263111: Yayy! New best EMA pseudo Dice: 0.901 
2025-02-09 20:48:08.585868:  
2025-02-09 20:48:08.586289: Epoch 37 
2025-02-09 20:48:08.586394: Current learning rate: 0.00967 
2025-02-09 20:55:01.413907: train_loss -0.9196 
2025-02-09 20:55:01.417474: val_loss -0.8635 
2025-02-09 20:55:01.417608: Pseudo dice [0.9504, 0.9715, 0.8323] 
2025-02-09 20:55:01.418566: Epoch time: 412.83 s 
2025-02-09 20:55:01.418746: Yayy! New best EMA pseudo Dice: 0.9027 
2025-02-09 20:55:03.497817:  
2025-02-09 20:55:03.498495: Epoch 38 
2025-02-09 20:55:03.498603: Current learning rate: 0.00966 
2025-02-09 21:01:54.968236: train_loss -0.9201 
2025-02-09 21:01:54.973007: val_loss -0.8691 
2025-02-09 21:01:54.973325: Pseudo dice [0.9482, 0.9733, 0.8317] 
2025-02-09 21:01:54.974357: Epoch time: 411.47 s 
2025-02-09 21:01:54.974450: Yayy! New best EMA pseudo Dice: 0.9042 
2025-02-09 21:01:56.812785:  
2025-02-09 21:01:56.813187: Epoch 39 
2025-02-09 21:01:56.813285: Current learning rate: 0.00965 
2025-02-09 21:08:34.321604: train_loss -0.9119 
2025-02-09 21:08:34.324431: val_loss -0.8483 
2025-02-09 21:08:34.324550: Pseudo dice [0.9424, 0.9707, 0.7742] 
2025-02-09 21:08:34.325397: Epoch time: 397.51 s 
2025-02-09 21:08:35.350956:  
2025-02-09 21:08:35.351125: Epoch 40 
2025-02-09 21:08:35.351232: Current learning rate: 0.00964 
2025-02-09 21:15:10.229995: train_loss -0.9111 
2025-02-09 21:15:10.232503: val_loss -0.8731 
2025-02-09 21:15:10.232608: Pseudo dice [0.9483, 0.9714, 0.8039] 
2025-02-09 21:15:10.233322: Epoch time: 394.88 s 
2025-02-09 21:15:11.237819:  
2025-02-09 21:15:11.238054: Epoch 41 
2025-02-09 21:15:11.238163: Current learning rate: 0.00963 
2025-02-09 21:21:47.091270: train_loss -0.9189 
2025-02-09 21:21:47.093826: val_loss -0.8895 
2025-02-09 21:21:47.093957: Pseudo dice [0.9491, 0.9721, 0.8553] 
2025-02-09 21:21:47.094794: Epoch time: 395.85 s 
2025-02-09 21:21:47.095118: Yayy! New best EMA pseudo Dice: 0.906 
2025-02-09 21:21:48.958801:  
2025-02-09 21:21:48.959274: Epoch 42 
2025-02-09 21:21:48.959647: Current learning rate: 0.00962 
2025-02-09 21:28:28.189848: train_loss -0.9135 
2025-02-09 21:28:28.191678: val_loss -0.842 
2025-02-09 21:28:28.191809: Pseudo dice [0.9494, 0.9696, 0.7913] 
2025-02-09 21:28:28.192602: Epoch time: 399.23 s 
2025-02-09 21:28:29.220249:  
2025-02-09 21:28:29.220668: Epoch 43 
2025-02-09 21:28:29.220765: Current learning rate: 0.00961 
2025-02-09 21:35:08.059398: train_loss -0.9185 
2025-02-09 21:35:08.061947: val_loss -0.8783 
2025-02-09 21:35:08.062422: Pseudo dice [0.9455, 0.9735, 0.8555] 
2025-02-09 21:35:08.063145: Epoch time: 398.84 s 
2025-02-09 21:35:08.063289: Yayy! New best EMA pseudo Dice: 0.9077 
2025-02-09 21:35:12.796838:  
2025-02-09 21:35:12.797132: Epoch 44 
2025-02-09 21:35:12.797304: Current learning rate: 0.0096 
2025-02-09 21:41:56.603249: train_loss -0.9178 
2025-02-09 21:41:56.606251: val_loss -0.8855 
2025-02-09 21:41:56.606388: Pseudo dice [0.9504, 0.9743, 0.8468] 
2025-02-09 21:41:56.607203: Epoch time: 403.81 s 
2025-02-09 21:41:56.607450: Yayy! New best EMA pseudo Dice: 0.9093 
2025-02-09 21:41:58.528180:  
2025-02-09 21:41:58.529017: Epoch 45 
2025-02-09 21:41:58.529130: Current learning rate: 0.00959 
2025-02-09 21:48:35.602232: train_loss -0.9076 
2025-02-09 21:48:35.604357: val_loss -0.864 
2025-02-09 21:48:35.604730: Pseudo dice [0.9455, 0.9728, 0.7993] 
2025-02-09 21:48:35.605369: Epoch time: 397.07 s 
2025-02-09 21:48:36.647192:  
2025-02-09 21:48:36.647567: Epoch 46 
2025-02-09 21:48:36.647699: Current learning rate: 0.00959 
2025-02-09 21:55:10.374405: train_loss -0.9095 
2025-02-09 21:55:10.377620: val_loss -0.8496 
2025-02-09 21:55:10.377925: Pseudo dice [0.9419, 0.9718, 0.7938] 
2025-02-09 21:55:10.378896: Epoch time: 393.73 s 
2025-02-09 21:55:11.353761:  
2025-02-09 21:55:11.354105: Epoch 47 
2025-02-09 21:55:11.354228: Current learning rate: 0.00958 
2025-02-09 22:01:40.992404: train_loss -0.9077 
2025-02-09 22:01:40.994790: val_loss -0.8614 
2025-02-09 22:01:40.994962: Pseudo dice [0.9443, 0.9713, 0.8157] 
2025-02-09 22:01:40.995611: Epoch time: 389.64 s 
2025-02-09 22:01:41.898223:  
2025-02-09 22:01:41.898443: Epoch 48 
2025-02-09 22:01:41.898563: Current learning rate: 0.00957 
2025-02-09 22:08:48.196280: train_loss -0.916 
2025-02-09 22:08:48.198900: val_loss -0.8824 
2025-02-09 22:08:48.199076: Pseudo dice [0.9465, 0.9707, 0.8625] 
2025-02-09 22:08:48.200421: Epoch time: 426.3 s 
2025-02-09 22:08:48.200605: Yayy! New best EMA pseudo Dice: 0.9103 
2025-02-09 22:08:50.056000:  
2025-02-09 22:08:50.056508: Epoch 49 
2025-02-09 22:08:50.056634: Current learning rate: 0.00956 
2025-02-09 22:15:25.908178: train_loss -0.9137 
2025-02-09 22:15:25.911132: val_loss -0.8707 
2025-02-09 22:15:25.911251: Pseudo dice [0.9481, 0.9731, 0.8113] 
2025-02-09 22:15:25.912312: Epoch time: 395.85 s 
2025-02-09 22:15:26.995197: Yayy! New best EMA pseudo Dice: 0.9104 
2025-02-09 22:15:28.325455:  
2025-02-09 22:15:28.325817: Epoch 50 
2025-02-09 22:15:28.325937: Current learning rate: 0.00955 
2025-02-09 22:22:03.013304: train_loss -0.915 
2025-02-09 22:22:03.015924: val_loss -0.8646 
2025-02-09 22:22:03.016056: Pseudo dice [0.9411, 0.9738, 0.8112] 
2025-02-09 22:22:03.016785: Epoch time: 394.69 s 
2025-02-09 22:22:03.944775:  
2025-02-09 22:22:03.945240: Epoch 51 
2025-02-09 22:22:03.945366: Current learning rate: 0.00954 
2025-02-09 22:28:43.094980: train_loss -0.9223 
2025-02-09 22:28:43.100537: val_loss -0.8819 
2025-02-09 22:28:43.100943: Pseudo dice [0.9489, 0.9755, 0.846] 
2025-02-09 22:28:43.101722: Epoch time: 399.15 s 
2025-02-09 22:28:43.101828: Yayy! New best EMA pseudo Dice: 0.9115 
2025-02-09 22:28:46.375783:  
2025-02-09 22:28:46.376015: Epoch 52 
2025-02-09 22:28:46.376119: Current learning rate: 0.00953 
2025-02-09 22:35:25.711135: train_loss -0.9141 
2025-02-09 22:35:25.713843: val_loss -0.8636 
2025-02-09 22:35:25.714171: Pseudo dice [0.9476, 0.9724, 0.8316] 
2025-02-09 22:35:25.715191: Epoch time: 399.34 s 
2025-02-09 22:35:25.715284: Yayy! New best EMA pseudo Dice: 0.9121 
2025-02-09 22:35:27.565045:  
2025-02-09 22:35:27.565714: Epoch 53 
2025-02-09 22:35:27.565901: Current learning rate: 0.00952 
2025-02-09 22:42:05.490440: train_loss -0.9149 
2025-02-09 22:42:05.492930: val_loss -0.855 
2025-02-09 22:42:05.493053: Pseudo dice [0.9431, 0.9709, 0.8116] 
2025-02-09 22:42:05.494088: Epoch time: 397.93 s 
2025-02-09 22:42:06.584110:  
2025-02-09 22:42:06.584371: Epoch 54 
2025-02-09 22:42:06.584528: Current learning rate: 0.00951 
2025-02-09 22:48:38.302819: train_loss -0.9199 
2025-02-09 22:48:38.305754: val_loss -0.8764 
2025-02-09 22:48:38.305874: Pseudo dice [0.9374, 0.9736, 0.8601] 
2025-02-09 22:48:38.306720: Epoch time: 391.72 s 
2025-02-09 22:48:38.306832: Yayy! New best EMA pseudo Dice: 0.9129 
2025-02-09 22:48:40.143448:  
2025-02-09 22:48:40.144035: Epoch 55 
2025-02-09 22:48:40.144153: Current learning rate: 0.0095 
2025-02-09 22:55:06.694794: train_loss -0.9226 
2025-02-09 22:55:06.698061: val_loss -0.903 
2025-02-09 22:55:06.698611: Pseudo dice [0.9488, 0.9743, 0.8803] 
2025-02-09 22:55:06.699580: Epoch time: 386.55 s 
2025-02-09 22:55:06.699678: Yayy! New best EMA pseudo Dice: 0.9151 
2025-02-09 22:55:08.527513:  
2025-02-09 22:55:08.527893: Epoch 56 
2025-02-09 22:55:08.528019: Current learning rate: 0.00949 
